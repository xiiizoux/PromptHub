# 后端API服务器配置
PORT=9010
# 前端服务器配置
FRONTEND_PORT=9011

# 传输类型配置 (stdio 用于本地运行, sse 用于远程模式)
TRANSPORT_TYPE=stdio

# API 身份验证密钥
API_KEY=your-secure-api-key

# MCP 服务器密钥 (用于 mcprouter 连接)
SERVER_KEY=your-secure-api-key

# 存储类型
STORAGE_TYPE=supabase

# Supabase 配置 (前后端共用)
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_ANON_KEY=your-anon-key

# Supabase前端需要添加NEXT_PUBLIC_前缀的变量
NEXT_PUBLIC_SUPABASE_URL=https://your-project-id.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key

# Google OAuth 配置
NEXT_PUBLIC_GOOGLE_CLIENT_ID=your-google-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=your-google-client-secret

# JWT配置
JWT_SECRET=your-jwt-secret
JWT_EXPIRES_IN=7d

# AI分析服务配置
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI兼容API配置 (支持自定义端点)
OPENAI_API_BASE_URL=https://api.openai.com/v1
# 示例替代配置:
# OPENAI_API_BASE_URL=http://localhost:11434/v1  # Ollama
# OPENAI_API_BASE_URL=https://api.deepseek.com/v1  # DeepSeek
# OPENAI_API_BASE_URL=https://api.moonshot.cn/v1  # Moonshot
# OPENAI_API_BASE_URL=https://api.zhipuai.cn/api/paas/v4  # GLM

# 模型配置
AI_MODEL_FULL_ANALYSIS=gpt-4
AI_MODEL_QUICK_TASKS=gpt-3.5-turbo
# 本地模型示例:
# AI_MODEL_FULL_ANALYSIS=llama3:8b
# AI_MODEL_QUICK_TASKS=qwen2:7b

# 复制此文件为 .env 并填入真实的配置值

# 额外的环境变量配置
COMPOSE_BAKE=true
API_URL=http://localhost:9010
BACKEND_URL=http://localhost:9010
MCP_URL=http://localhost:9010
CORS_ORIGIN=*
NODE_ENV=development